# -*- coding: utf-8 -*-
"""
Step 5A (Patched - Ranking Friendly, No Tier Dependency)
--------------------------------------------------------
åŠŸèƒ½ï¼š
- ä» step4c_master_summary.csv ä¸­é€‰ Top N åˆ†å­ï¼ˆé»˜è®¤æŒ‰ R_global ä¼˜å…ˆï¼‰
- å¯¹æ¯ä¸ªåˆ†å­å¯¹æ¥åˆ°å¤šç§å† çŠ¶ç—…æ¯’ Mpro
- è§£ææ¯ä¸ªé¶ç‚¹ç»“åˆèƒ½ï¼Œè®¡ç®— Broad_Spectrum_Score
- è¾“å‡º step5a_broadspectrum_docking.csv
- é¢å¤–ï¼šåœ¨è¾“å‡º CSV ä¸­åŠ å…¥ Broad_Rank / Broad_Rank_Pctï¼ˆæŒ‰ Broad_Spectrum_Score æ’åï¼‰

å…³é”®æ”¹åŠ¨ï¼š
1) Broad_Spectrum_Score ï¼šå¯¹æ‰€æœ‰é¶ç‚¹çš„æœ‰æ•ˆæ•°å€¼éƒ½è®¡å…¥æœ€å·®é¶ç‚¹ï¼ˆmaxï¼‰ã€‚
2) è¾“å‡ºè‡ªå¸¦æ’ååˆ—ï¼Œä¾¿äº Step5B ç›´æ¥æŒ‰æ’åå– TopKï¼Œé¿å…é˜ˆå€¼åˆ†çº§å¯¼è‡´â€œå…¨ç­â€ã€‚

"""

import os
import sys
import argparse
import subprocess
import tempfile
import shutil
import concurrent.futures
from typing import Dict, Any, Optional, List
import glob

import numpy as np
import pandas as pd
from rdkit import Chem
from rdkit.Chem import AllChem

# ----------------- è·¯å¾„åŸºç¡€è®¾ç½® ----------------- #
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, ".."))

DEFAULT_INPUT_CSV = os.path.join(project_root, "results", "step4c_master_summary.csv")
DEFAULT_OUT_CSV = os.path.join(project_root, "results", "step5a_broadspectrum_docking.csv")
DEFAULT_RECEPTOR_DIR = os.path.join(project_root, "data", "receptors")


# ----------------- Grid Box é…ç½®ï¼ˆä¿æŒä¸ä½ å½“å‰ç‰ˆæœ¬ä¸€è‡´ï¼‰----------------- #
TARGET_CONFIG: Dict[str, Dict[str, Any]] = {
    "SARS_CoV_2": {
        "file": "6W63_gast_clean.pdbqt",
        "box": {"center_x": -17.369, "center_y": 18.129, "center_z": -31.220, "size_x": 24.0, "size_y": 24.0, "size_z": 24.0},
    },
    "SARS_CoV_1": {
        "file": "3V3M_gast_clean.pdbqt",
        "box": {"center_x": 21.845, "center_y": -31.086, "center_z": -4.129, "size_x": 24.0, "size_y": 24.0, "size_z": 24.0},
    },
    "MERS_CoV": {
        "file": "4YLU_gast_clean.pdbqt",
        "box": {"center_x": 27.1, "center_y": -26.2, "center_z": 69.1, "size_x": 24.0, "size_y": 24.0, "size_z": 24.0},
    },
}



# ===================== Stage2 Guardrails é…ç½®å— =====================
# ç›®æ ‡ï¼šåœ¨â€œä»£ç†æ¨¡å‹ predE3 æ’åºâ€ä¹‹åï¼Œç”¨å°‘é‡å¯è§£é‡Šçš„ç†åŒ–é—¸é—¨æŠŠæ˜æ˜¾æ‰é˜Ÿçš„ç»“æ„ç±»å‹æŒ¡åœ¨ docking ä¹‹å¤–ï¼Œ
#      ä»¥æå‡ TopN çš„ç¨³å®šæ€§ï¼ˆå°¤å…¶æ˜¯é¿å…å‡ºç° broad å°¾å·´åˆ†å­ï¼‰ã€‚
#
# ä½ å¯ä»¥æŠŠå®ƒç†è§£ä¸ºï¼š**ä¸é’ˆå¯¹æŸä¸€æ‰¹åˆ†å­è°ƒå‚**ï¼Œè€Œæ˜¯å›ºåŒ–â€œè·¨æ‰¹æ¬¡éƒ½æˆç«‹â€çš„ç»“æ„å¸¸è¯†ã€‚
#
# å‚æ•°å«ä¹‰ï¼š
# - pool:         å…ˆä»æ’åºç»“æœé‡Œå–å‰ pool ä¸ªä½œä¸ºå€™é€‰æ± ï¼ˆpool è¶Šå¤§ï¼Œè¶Šä¸å®¹æ˜“å› ä¸º ADMET/é—¸é—¨è¿‡æ»¤åä¸å¤Ÿ 100 ä¸ªï¼‰
# - mw_min:       åˆ†å­åˆ«å¤ªå°ï¼›å¤ªå°å¾€å¾€é”šç‚¹ä¸å¤Ÿã€å¯¹æ¥ä¸ç¨³ï¼ˆä½ è¿™é‡Œç»éªŒä¸Š 260 æ˜¯ä¸ªå®‰å…¨ä¸‹é™ï¼‰
# - tpsa_min:     ææ€§/æ°¢é”®è¡¨é¢ç§¯ä¸‹é™ï¼›å¤ªä½å¸¸è§â€œæŠ“ä¸ä½å£è¢‹â€ â†’ broad å°¾å·´ï¼ˆä½ å·²ç»éªŒè¯ TPSA>=35 èƒ½æ˜¾è‘—å‰ªå°¾å·´ï¼‰
# - hba_min:      å—ä½“æ°¢é”®å—ä½“æ•°ä¸‹é™ï¼›HBA å¤ªå°‘ï¼ˆä¾‹å¦‚ 1ï¼‰å®¹æ˜“å‡ºç° hard-negativeï¼ˆå¦‚ mol_95 ç±»å‹ï¼‰
# - soft_tpsa_target:
#                è½¯ç›®æ ‡ï¼šTPSA ä½äºè¯¥å€¼æ—¶ï¼Œä¸ç›´æ¥ç æ‰ï¼Œè€Œæ˜¯ç»™ä¸€ç‚¹â€œæ’åºæƒ©ç½šâ€ï¼ŒæŠŠå®ƒå¾€åæ’ï¼ˆé»˜è®¤ 45ï¼‰
# - soft_logp_max:
#                è½¯ç›®æ ‡ï¼šLogP é«˜äºè¯¥å€¼æ—¶ç»™ä¸€ç‚¹æƒ©ç½šï¼Œé¿å…è¿‡ç–æ°´å¯¼è‡´ pose ä¸ç¨³å®š/ADMET è¾¹ç¼˜ï¼ˆé»˜è®¤ 4.8ï¼‰
# - penalty_tpsa / penalty_logp:
#                æƒ©ç½šå¼ºåº¦ï¼ˆè¶Šå¤§è¶Šâ€œä¸¥æ ¼â€ï¼‰ï¼›ä¸€èˆ¬ä¸å»ºè®®é¢‘ç¹æ”¹ï¼Œé™¤éä½ å‘ç°å°¾å·´åˆå›æ½®ã€‚
#
# æä¾› 3 ä¸ªé¢„è®¾ profileï¼š
# - strict  : æ›´ä¸¥æ ¼å‰ªå°¾å·´ï¼ˆæ›´ç¨³ï¼Œä½†å¯èƒ½å¯ç”¨åˆ†å­æ›´å°‘ï¼‰
# - balanced: é»˜è®¤æ¨èï¼ˆä½ ç›®å‰éªŒè¯æœ€æ¥è¿‘è¿™ä¸ªï¼‰
# - loose   : æ›´å®½æ¾ï¼ˆé€‚åˆä½ æ‹…å¿ƒè¿‡æ»¤åä¸å¤Ÿ 100 ä¸ªæ—¶ï¼‰
STAGE2_PROFILES = {
    "strict": {
        "pool": 1000,
        "mw_min": 280.0,
        "tpsa_min": 40.0,
        "hba_min": 2,
        "soft_tpsa_target": 55.0,
        "soft_logp_max": 4.6,
        "penalty_tpsa": 0.04,
        "penalty_logp": 0.35,
    },
    "balanced": {
        "pool": 800,
        "mw_min": 260.0,
        "tpsa_min": 35.0,
        "hba_min": 2,
        "soft_tpsa_target": 45.0,
        "soft_logp_max": 4.8,
        "penalty_tpsa": 0.03,
        "penalty_logp": 0.30,
    },
    "loose": {
        "pool": 800,
        "mw_min": 260.0,
        "tpsa_min": 30.0,
        "hba_min": 2,
        "soft_tpsa_target": 40.0,
        "soft_logp_max": 5.2,
        "penalty_tpsa": 0.02,
        "penalty_logp": 0.20,
    },
}
DEFAULT_STAGE2_PROFILE = "balanced"


# ===================== predE3 ä»£ç†æ¨¡å‹è®­ç»ƒé…ç½®å—ï¼ˆè½»é‡é»˜è®¤ï¼‰ =====================
# è¯´æ˜ï¼šè¿™éƒ¨åˆ†ä¸»è¦æ§åˆ¶è®­ç»ƒé€Ÿåº¦/ç¨³å®šæ€§ã€‚é»˜è®¤å‚æ•°æ˜¯â€œå¾ˆå¿«èƒ½è·‘å®Œâ€çš„ç‰ˆæœ¬ã€‚
PRED_E3_DEFAULT = {
    "n_estimators": 300,   # ç¨³å®šåå¯å‡åˆ° 600/800
    "cv_splits": 3,        # ç¨³å®šåå¯å‡åˆ° 5
    "min_samples_leaf": 2,
    "random_state": 0,
}


def resolve_receptor_path(receptor_dir: str, base_filename: str) -> Optional[str]:
    """ä¼˜å…ˆä½¿ç”¨ *_gast_clean.pdbqtï¼›å¦åˆ™å›é€€åˆ°åŸæ–‡ä»¶åã€‚"""
    # å¦‚æœåŸæœ¬å·²ç»æ˜¯ gast_cleanï¼Œåˆ™ç›´æ¥ä½¿ç”¨
    candidates: List[str] = []
    if base_filename.endswith("_gast_clean.pdbqt"):
        candidates.append(base_filename)
    else:
        stem = base_filename[:-6] if base_filename.endswith(".pdbqt") else base_filename
        candidates.append(f"{stem}_gast_clean.pdbqt")
        candidates.append(base_filename)

    for fn in candidates:
        p = os.path.join(receptor_dir, fn)
        if os.path.exists(p) and os.path.getsize(p) > 0:
            return p
    return None


def pocket_center_from_pdbqt(rec_pdbqt: str, his_resi: int = 41, cys_resi: int = 145) -> Optional[Dict[str, float]]:
    """
    ä»å—ä½“ PDBQT è§£æ Mpro å£è¢‹ä¸­å¿ƒï¼šå– His41(NE2/ND1) ä¸ Cys145(SG) çš„ä¸­ç‚¹ã€‚
    - ä¸ä¾èµ– PDB æ–‡ä»¶ï¼ˆç›´æ¥ç”¨ pdbqt å†…çš„æ®‹åŸº/åŸå­/åæ ‡å­—æ®µï¼‰
    - è‹¥ NE2 ä¸å­˜åœ¨ï¼Œåˆ™å°è¯• ND1
    è¿”å›: {"center_x":..., "center_y":..., "center_z":...} æˆ– None
    """
    his_resnames = {"HIS", "HIE", "HID", "HIP"}
    hx = hy = hz = None
    cx = cy = cz = None

    def try_find(his_atom: str) -> bool:
        nonlocal hx, hy, hz, cx, cy, cz
        hx = hy = hz = None
        cx = cy = cz = None
        try:
            with open(rec_pdbqt, "r", encoding="utf-8", errors="ignore") as f:
                for ln in f:
                    if not (ln.startswith("ATOM") or ln.startswith("HETATM")):
                        continue
                    parts = ln.split()
                    # æœŸæœ›æ ¼å¼ï¼šATOM serial atom res chain resi x y z ...
                    if len(parts) < 9:
                        continue
                    atom = parts[2]
                    resn = parts[3]
                    try:
                        resi = int(parts[5])
                    except Exception:
                        continue
                    try:
                        x = float(parts[6]); y = float(parts[7]); z = float(parts[8])
                    except Exception:
                        continue

                    if resi == cys_resi and resn == "CYS" and atom == "SG":
                        cx, cy, cz = x, y, z
                    if resi == his_resi and resn in his_resnames and atom == his_atom:
                        hx, hy, hz = x, y, z

                    if (hx is not None) and (cx is not None):
                        break
        except Exception:
            return False

        return (hx is not None) and (cx is not None)

    ok = try_find("NE2")
    if not ok:
        ok = try_find("ND1")
    if not ok:
        return None

    return {
        "center_x": (hx + cx) / 2.0,
        "center_y": (hy + cy) / 2.0,
        "center_z": (hz + cz) / 2.0,
    }


def build_resolved_target_config(receptor_dir: str) -> Dict[str, Dict[str, Any]]:
    """æ„å»ºä¸€ä¸ªâ€œå¯ç›´æ¥ç”¨äº dockingâ€çš„ TARGET_CONFIG å‰¯æœ¬ï¼šè§£æå—ä½“è·¯å¾„ + è‡ªåŠ¨å£è¢‹ä¸­å¿ƒã€‚"""
    resolved: Dict[str, Dict[str, Any]] = {}
    for virus, conf in TARGET_CONFIG.items():
        base_file = conf["file"]
        rec_path = resolve_receptor_path(receptor_dir, base_file)

        box = dict(conf["box"])  # copy
        if rec_path is None:
            print(f"âš ï¸ å—ä½“ç¼ºå¤±: {virus} | æœŸæœ› {base_file} æˆ– *_gast_clean.pdbqt")
            resolved[virus] = {"path": None, "box": box, "file": base_file}
            continue

        # è‡ªåŠ¨è®¡ç®—å£è¢‹ä¸­å¿ƒï¼›å¤±è´¥åˆ™å›é€€é…ç½®ä¸­å¿ƒ
        cen = pocket_center_from_pdbqt(rec_path)
        if cen is not None:
            box.update(cen)
            print(
                f"ğŸ§­ {virus} box center(auto His41/Cys145) = "
                f"({box['center_x']:.3f}, {box['center_y']:.3f}, {box['center_z']:.3f}) "
                f"| receptor={os.path.basename(rec_path)}"
            )
        else:
            print(
                f"âš ï¸ {virus} æ— æ³•ä»å—ä½“è§£æ His41/Cys145ï¼ˆä¿æŒé…ç½®ä¸­å¿ƒï¼‰"
                f" | receptor={os.path.basename(rec_path)}"
            )

        resolved[virus] = {"path": rec_path, "box": box, "file": os.path.basename(rec_path)}
    return resolved


def choose_sort_col(df: pd.DataFrame, preferred: List[str]) -> Optional[str]:
    for c in preferred:
        if c in df.columns and df[c].notna().any():
            return c
    return None


def smiles_to_3d_pdb(smiles: str, out_pdb: str) -> bool:
    """RDKit ç”Ÿæˆ 3D PDB"""
    try:
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            return False
        mol = Chem.AddHs(mol)
        ps = AllChem.ETKDG()
        ps.randomSeed = 42
        if AllChem.EmbedMolecule(mol, ps) != 0:
            return False
        AllChem.MMFFOptimizeMolecule(mol)
        Chem.MolToPDBFile(mol, out_pdb)
        return True
    except Exception:
        return False


def run_cmd(cmd: List[str]) -> subprocess.CompletedProcess:
    return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)


def pdb_to_pdbqt_with_obabel(in_pdb: str, out_pdbqt: str) -> bool:
    """
    ç”¨ obabel è½¬ PDBQTï¼ˆä¿æŒä½ åŸè„šæœ¬çš„â€œpH 7.4 è´¨å­åŒ–â€æ€è·¯ï¼‰
    éœ€è¦ç³»ç»Ÿå®‰è£… OpenBabelï¼ˆobabelï¼‰
    """
    try:
        cmd = ["obabel", in_pdb, "-O", out_pdbqt, "--partialcharge", "gasteiger", "-p", "7.4"]
        res = run_cmd(cmd)
        return res.returncode == 0 and os.path.exists(out_pdbqt) and os.path.getsize(out_pdbqt) > 0
    except Exception:
        return False


def run_single_docking(lig_pdbqt: str, rec_pdbqt: str, box: Dict[str, float], cpu_per_task: int = 1) -> float:
    """
    è°ƒç”¨ vinaï¼Œè¿”å› best affinityï¼ˆkcal/molï¼‰
    éœ€è¦ç³»ç»Ÿå®‰è£… vina
    """
    out_pdbqt = lig_pdbqt.replace(".pdbqt", f"_out_{os.path.basename(rec_pdbqt)}")
    log_txt = lig_pdbqt.replace(".pdbqt", f"_{os.path.basename(rec_pdbqt)}.log")

    cmd = [
        "vina",
        "--receptor", rec_pdbqt,
        "--ligand", lig_pdbqt,
        "--center_x", str(box["center_x"]),
        "--center_y", str(box["center_y"]),
        "--center_z", str(box["center_z"]),
        "--size_x", str(box["size_x"]),
        "--size_y", str(box["size_y"]),
        "--size_z", str(box["size_z"]),
        "--cpu", str(cpu_per_task),
        "--exhaustiveness", "8",
        "--num_modes", "1",
        "--out", out_pdbqt,
        "--log", log_txt,
    ]

    res = run_cmd(cmd)
    if res.returncode != 0:
        return np.nan

    # ä» log ä¸­è§£æ affinity
    try:
        with open(log_txt, "r", encoding="utf-8", errors="ignore") as f:
            lines = f.read().splitlines()
        # vina log ä¸­é€šå¸¸æœ‰è¡¨æ ¼ï¼Œç¬¬ä¸€æ¡ mode çš„ affinity åœ¨æŸè¡Œ
        # è¿™é‡Œåšä¸€ä¸ªç¨³å¥è§£æï¼šæ‰¾åŒ…å« "1 " ä¸”æœ‰æµ®ç‚¹æ•°çš„è¡Œ
        for ln in lines:
            if ln.strip().startswith("1 "):
                parts = ln.split()
                # parts[1] é€šå¸¸æ˜¯ affinity
                return float(parts[1])
    except Exception:
        pass

    return np.nan


def process_one_molecule(row: pd.Series, target_conf: Dict[str, Dict[str, Any]], tmp_root: str, cpu_per_task: int) -> Optional[Dict[str, Any]]:
    name = str(row.get("name", row.get("id", "")))
    if not name:
        name = f"mol_{int(row.name)}"
    smiles = row.get("smiles", "")
    if not isinstance(smiles, str) or not smiles.strip():
        return None

    mol_dir = os.path.join(tmp_root, name)
    os.makedirs(mol_dir, exist_ok=True)

    lig_pdb = os.path.join(mol_dir, f"{name}.pdb")
    lig_pdbqt = os.path.join(mol_dir, f"{name}.pdbqt")

    # 1) RDKit -> PDB
    if not smiles_to_3d_pdb(smiles, lig_pdb):
        return None

    # 2) obabel -> PDBQT
    if not pdb_to_pdbqt_with_obabel(lig_pdb, lig_pdbqt):
        return None

    # 3) å¯¹æ¥åˆ°å¤šä¸ªé¶ç‚¹
    rec_scores: Dict[str, float] = {}
    finite_scores: List[float] = []

    for virus, conf in target_conf.items():
        rec_path = conf.get("path")
        if not rec_path or (not os.path.exists(rec_path)):
            rec_scores[virus] = np.nan
            continue

        score = run_single_docking(
            lig_pdbqt=lig_pdbqt,
            rec_pdbqt=rec_path,
            box=conf["box"],
            cpu_per_task=cpu_per_task,
        )
        rec_scores[virus] = score
        if score is not None and np.isfinite(score):
            finite_scores.append(float(score))

    # 4) Broad_Spectrum_Scoreï¼šå–â€œæœ€å·®é¶ç‚¹â€ï¼ˆmaxï¼Œè¶Šè´Ÿè¶Šå¥½ï¼‰
    if not finite_scores:
        broad_score = np.nan
    else:
        broad_score = max(finite_scores)

    record: Dict[str, Any] = {
        "name": name,
        "smiles": smiles,
        "Broad_Spectrum_Score": broad_score,
    }

    # 5) å›å¡«ä¸Šæ¸¸ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    for key in ["pIC50", "Reward", "R_total2", "R_total", "R_ADMET", "R_global"]:
        if key in row.index:
            record[key] = row[key]

    # 6) å„é¶ç‚¹åˆ†æ•°
    for virus, sc in rec_scores.items():
        record[f"E_{virus}"] = sc

    return record


def compute_rank_pct(scores: pd.Series) -> pd.Series:
    n = int(scores.notna().sum())
    if n <= 0:
        return pd.Series([np.nan] * len(scores), index=scores.index)
    rank = scores.rank(method="min", ascending=True)
    return rank / float(n)


# ===================== predE3 + Stage2 è‡ªåŠ¨æ’åº/è¿‡æ»¤ =====================
def _load_docking_labels(dock_csv_glob: str) -> pd.DataFrame:
    '''
    è¯»å–å†å² docking ç»“æœä½œä¸ºç›‘ç£æ ‡ç­¾ã€‚
    æœŸæœ›åˆ—ï¼šsmiles, E_SARS_CoV_2, E_SARS_CoV_1, E_MERS_CoV, Broad_Spectrum_Score
    åŒä¸€ä¸ª smiles å¤šæ¬¡å‡ºç°æ—¶ï¼Œä¿ç•™ Broad_Spectrum_Score æœ€å¥½çš„ï¼ˆæœ€è´Ÿçš„é‚£æ¡ï¼‰ã€‚
    '''
    import glob

    need = ["smiles", "E_SARS_CoV_2", "E_SARS_CoV_1", "E_MERS_CoV", "Broad_Spectrum_Score"]
    dfs: List[pd.DataFrame] = []
    for p in glob.glob(dock_csv_glob):
        try:
            d = pd.read_csv(p)
        except Exception:
            continue
        if all(c in d.columns for c in need):
            dfs.append(d[need].copy())
    if not dfs:
        return pd.DataFrame(columns=need)

    dock = pd.concat(dfs, ignore_index=True)
    dock = dock.sort_values("Broad_Spectrum_Score").drop_duplicates("smiles", keep="first")
    return dock


def _train_predE3_and_rank(step4c_df: pd.DataFrame,
                          dock_labels: pd.DataFrame,
                          n_estimators: int,
                          cv_splits: int,
                          n_jobs: int,
                          min_samples_leaf: int = 2,
                          random_state: int = 0) -> pd.DataFrame:
    '''
    è®­ç»ƒå¤šè¾“å‡º RFï¼šåŒæ—¶é¢„æµ‹ä¸‰ä¸ªé¶ç‚¹èƒ½é‡ã€‚
    è¿”å›å¸¦ pred_* åˆ—ã€å¹¶æŒ‰ pred_broadï¼ˆè¶Šå°è¶Šå¥½ï¼‰æ’åºçš„ dfã€‚
    '''
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import KFold

    if dock_labels.empty:
        raise RuntimeError("No docking labels loaded (dock_labels is empty).")

    m = step4c_df.merge(dock_labels, on="smiles", how="inner")
    if len(m) < 50:
        raise RuntimeError(f"Too few labeled rows to train predE3: {len(m)}")

    # ç”¨ step4c çš„æ•°å€¼åˆ—åšç‰¹å¾ï¼›å‰”é™¤æ˜æ˜¾â€œæ ‡ç­¾/çŠ¶æ€/å¥–åŠ±â€åˆ—
    drop_cols = set([
        "Reward", "R_total", "R_global", "R_total2",
        "Is_Final_Top", "Filter_Status", "Active_Set", "Data_Source_Status",
        "status", "Calc_Method",
    ])
    num_cols = [c for c in step4c_df.columns if pd.api.types.is_numeric_dtype(step4c_df[c])]
    feat_cols = [c for c in num_cols if c not in drop_cols]

    X = m[feat_cols].replace([np.inf, -np.inf], np.nan)
    X = X.fillna(X.median(numeric_only=True))
    Y = m[["E_SARS_CoV_2", "E_SARS_CoV_1", "E_MERS_CoV"]].astype(float)

    # è½»é‡ CVï¼ˆä¸»è¦ sanity checkï¼‰
    kf = KFold(n_splits=cv_splits, shuffle=True, random_state=random_state)
    maes = []
    for tr, te in kf.split(X):
        model = RandomForestRegressor(
            n_estimators=n_estimators,
            random_state=random_state,
            n_jobs=n_jobs,
            min_samples_leaf=min_samples_leaf,
        )
        model.fit(X.iloc[tr], Y.iloc[tr])
        pred = model.predict(X.iloc[te])
        maes.append(float(np.mean(np.abs(pred - Y.iloc[te].values))))
    print(f"[predE3] CV MAE(mean over 3 targets) = {np.mean(maes):.3f} Â± {np.std(maes):.3f}")

    # å…¨é‡è®­ç»ƒ
    model = RandomForestRegressor(
        n_estimators=n_estimators,
        random_state=random_state,
        n_jobs=n_jobs,
        min_samples_leaf=min_samples_leaf,
    )
    model.fit(X, Y)

    # å…¨é‡é¢„æµ‹
    X_all = step4c_df[feat_cols].replace([np.inf, -np.inf], np.nan)
    X_all = X_all.fillna(X_all.median(numeric_only=True))
    pred_all = model.predict(X_all)

    df_out = step4c_df.copy()
    df_out["pred_E_SARS_CoV_2"] = pred_all[:, 0]
    df_out["pred_E_SARS_CoV_1"] = pred_all[:, 1]
    df_out["pred_E_MERS_CoV"] = pred_all[:, 2]
    df_out["pred_broad"] = df_out[["pred_E_SARS_CoV_2", "pred_E_SARS_CoV_1", "pred_E_MERS_CoV"]].max(axis=1)

    # å…¼å®¹ step5a çš„ TopN é€‰æ‹©ï¼šæŠŠ R_global ä¸´æ—¶æ›¿æ¢ä¸º -pred_broadï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
    if "R_global" in df_out.columns:
        df_out["R_global_bak_predE3"] = df_out["R_global"]
    df_out["R_global"] = -df_out["pred_broad"]
    df_out = df_out.sort_values("R_global", ascending=False)
    return df_out


def _apply_stage2_guardrails(
    df_ranked: pd.DataFrame,
    cfg: Dict[str, Any],
    use_strict_gate: bool,
    rphys_min: float
) -> pd.DataFrame:

    '''
    Stage2ï¼šåœ¨â€œæ’åºåâ€å†è¿‡æ»¤/é‡æ’ï¼ˆé¿å… hard-negative å°¾å·´ï¼‰ã€‚
    - å…ˆæŒ‰ step5a é€»è¾‘ä¿æŒ Active_Set==Trueï¼ˆå¦‚æœæœ‰ï¼‰
    - å–å‰ pool
    - ç¡¬é—¸é—¨ï¼šMW/TPSA/HBA
    - è½¯æƒ©ç½šï¼šTPSA ä½äº soft_tpsa_targetã€LogP é«˜äº soft_logp_max
    '''
    df = df_ranked.copy()

    
    # ä¸ main() é€»è¾‘ä¿æŒä¸€è‡´ï¼šåªæœ‰å¼€å¯ --use_strict_gate æ‰å¯ç”¨ä¸¥æ ¼é—¨æ§›
    if use_strict_gate and all(c in df.columns for c in ["Data_Source_Status", "Physical_HardFail", "R_phys"
    ]):
        df = df[
            (df["Data_Source_Status"] == "Step3c+4a+4b") &
            (df["Physical_HardFail"] == False) &
            (df["R_phys"] >= float(rphys_min))
        ].copy()
    elif "Is_Final_Top" in df.columns:
        df = df[df["Is_Final_Top"] == True].copy()
    elif "Active_Set" in df.columns:
        df = df[(df["Active_Set"] == True) | (df["Active_Set"] == 1)].copy()

    pool = int(cfg["pool"])
    df = df.head(pool).copy()

    # ç¡¬é—¸é—¨
    df = df[(df["MW"] >= float(cfg["mw_min"])) &
            (df["TPSA"] >= float(cfg["tpsa_min"])) &
            (df["HBA"] >= int(cfg["hba_min"]))].copy()

    # è½¯æƒ©ç½šï¼ˆåªå½±å“æ’åºï¼‰
    tpsa = df["TPSA"].astype(float)
    logp = df["LogP"].astype(float) if "LogP" in df.columns else pd.Series(np.zeros(len(df)), index=df.index)

    soft_tpsa_target = float(cfg["soft_tpsa_target"])
    soft_logp_max = float(cfg["soft_logp_max"])
    penalty_tpsa = float(cfg["penalty_tpsa"])
    penalty_logp = float(cfg["penalty_logp"])

    pen = penalty_tpsa * np.maximum(0.0, soft_tpsa_target - tpsa) + penalty_logp * np.maximum(0.0, logp - soft_logp_max)

    base = -df["pred_broad"].astype(float) if "pred_broad" in df.columns else df["R_global"].astype(float)
    df["R_global_bak_stage2"] = df["R_global"]
    df["R_global"] = base - pen
    df = df.sort_values("R_global", ascending=False)
    return df

def save_top_n_structures(df_results, tmp_root, top_n=20):
    """
    ä¿å­˜ Top N åˆ†å­çš„è‡ªç”±æ€ä¸å¯¹æ¥æ€ç»“æ„ï¼ˆåŒ¹é…å½“å‰è„šæœ¬å®é™…ç”Ÿæˆçš„æ–‡ä»¶åï¼‰
    """
    save_dir = os.path.join(project_root, "results", "step5a_top_structures")
    if os.path.exists(save_dir):
        shutil.rmtree(save_dir)
    os.makedirs(save_dir, exist_ok=True)

    # Broad_Spectrum_Score è¶Šè´Ÿè¶Šå¥½ï¼ˆå‡åºï¼‰
    df_top = df_results.sort_values("Broad_Spectrum_Score", ascending=True).head(top_n)

    print(f"\n>>> æ­£åœ¨æå– Top {top_n} åˆ†å­çš„ 3D ç»“æ„...")
    for _, row in df_top.iterrows():
        mol_name = str(row["name"])
        mol_src_dir = os.path.join(tmp_root, mol_name)
        mol_dst_dir = os.path.join(save_dir, mol_name)
        os.makedirs(mol_dst_dir, exist_ok=True)

        # 1) è‡ªç”±æ€ ligandï¼šå®é™…æ˜¯ {name}.pdbqt
        lig = os.path.join(mol_src_dir, f"{mol_name}.pdbqt")
        if os.path.exists(lig):
            shutil.copy(lig, os.path.join(mol_dst_dir, f"{mol_name}_free_ligand.pdbqt"))

        # 2) å¯¹æ¥æ€ï¼šå®é™…æ˜¯ {name}_out_*.pdbqt
        for p in glob.glob(os.path.join(mol_src_dir, f"{mol_name}_out_*.pdbqt")):
            shutil.copy(p, os.path.join(mol_dst_dir, os.path.basename(p)))

    print(f"âœ… ç»“æ„å·²ä¿å­˜è‡³: {save_dir}")



def main():
    parser = argparse.ArgumentParser(description="Step 5A: Broad-Spectrum Docking (Ranking-friendly)")
    parser.add_argument("--use_strict_gate", action="store_true",
                help="ä½¿ç”¨ä¸¥æ ¼MDé—¨æ§›ç­›é€‰ï¼šå¿…é¡»æœ‰PySCFä¸”Physical_HardFail=Falseä¸”R_phys>=é˜ˆå€¼")
    parser.add_argument("--rphys_min", type=float, default=0.85,
                help="ä¸¥æ ¼é—¨æ§›çš„ R_phys ä¸‹é™ï¼ˆé»˜è®¤ 0.85ï¼›å¯æ”¹ 0.80ï¼‰")
    
    parser.add_argument("--input_csv", type=str, default=DEFAULT_INPUT_CSV, help=f"è¾“å…¥ Step4C æ€»è¡¨ (é»˜è®¤: {DEFAULT_INPUT_CSV})")
    parser.add_argument("--out_csv", type=str, default=DEFAULT_OUT_CSV, help=f"è¾“å‡º docking ç»“æœ CSV (é»˜è®¤: {DEFAULT_OUT_CSV})")
    parser.add_argument("--receptor_dir", type=str, default=DEFAULT_RECEPTOR_DIR, help=f"å—ä½“ pdbqt æ‰€åœ¨ç›®å½• (é»˜è®¤: {DEFAULT_RECEPTOR_DIR})")
    parser.add_argument("--top_n", type=int, default=20, help="ä» Step4C ä¸­é€‰å‰ top_n ä¸ªåˆ†å­åš docking (é»˜è®¤: 20)")
    
    parser.add_argument("--workers", type=int, default=4, help="å¹¶è¡Œå¤„ç†çš„åˆ†å­æ•° (é»˜è®¤: 4)")
    parser.add_argument("--vina_cpu", type=int, default=1, help="æ¯ä¸ª Vina è¿›ç¨‹ä½¿ç”¨çš„ CPU æ•° (é»˜è®¤: 1)")
    # --- å›ºåŒ–æ¨¡å¼ï¼špredE3 ä»£ç†æ’åº + Stage2 guardrailsï¼ˆå¯é€‰å¯ç”¨ï¼‰ ---
    parser.add_argument("--auto_predE3_stage2", action="store_true",
                        help="å¯ç”¨ï¼šè‡ªåŠ¨ç”¨å†å² docking è®­ç»ƒ predE3ï¼Œå¹¶æ‰§è¡Œ Stage2 guardrails åå† dockï¼ˆæ¨èï¼‰")
    parser.add_argument("--step4c_csv", type=str, default=None,
                        help="Step4C master csvï¼ˆä¸å¡«åˆ™æ²¿ç”¨ --input_csvï¼‰")
    parser.add_argument("--dock_csv_glob", type=str, default=os.path.join(project_root, "results", "step5a_broadspectrum_docking*.csv"),
                        help="å†å² docking ç»“æœ globï¼Œç”¨äºè®­ç»ƒ predE3ï¼ˆé»˜è®¤: results/step5a_broadspectrum_docking*.csvï¼‰")

    # predE3 è®­ç»ƒå‚æ•°ï¼ˆé»˜è®¤è½»é‡å¿«é€Ÿï¼‰
    parser.add_argument("--predE3_n_estimators", type=int, default=PRED_E3_DEFAULT["n_estimators"])
    parser.add_argument("--predE3_cv_splits", type=int, default=PRED_E3_DEFAULT["cv_splits"])
    parser.add_argument("--predE3_n_jobs", type=int, default=40, help="predE3 è®­ç»ƒç”¨å¹¶è¡Œæ ¸æ•°ï¼ˆå»ºè®®<=CPUé…é¢ï¼‰")

    # Stage2 å‚æ•°ï¼šä¼˜å…ˆä½¿ç”¨ profileï¼Œå†ç”¨å•é¡¹å‚æ•°è¦†ç›–
    parser.add_argument("--stage2_profile", type=str, default=DEFAULT_STAGE2_PROFILE, choices=list(STAGE2_PROFILES.keys()),
                        help="Stage2 é¢„è®¾ï¼šstrict/balanced/looseï¼ˆé»˜è®¤ balancedï¼‰")
    parser.add_argument("--stage2_pool", type=int, default=None, help="è¦†ç›– profile.poolï¼ˆä¸å¡«åˆ™ç”¨ profile é»˜è®¤ï¼‰")
    parser.add_argument("--stage2_mw_min", type=float, default=None, help="è¦†ç›– profile.mw_min")
    parser.add_argument("--stage2_tpsa_min", type=float, default=None, help="è¦†ç›– profile.tpsa_min")
    parser.add_argument("--stage2_hba_min", type=int, default=None, help="è¦†ç›– profile.hba_min")
    parser.add_argument("--stage2_soft_tpsa_target", type=float, default=None, help="è¦†ç›– profile.soft_tpsa_target")
    parser.add_argument("--stage2_soft_logp_max", type=float, default=None, help="è¦†ç›– profile.soft_logp_max")
    parser.add_argument("--stage2_penalty_tpsa", type=float, default=None, help="è¦†ç›– profile.penalty_tpsa")
    parser.add_argument("--stage2_penalty_logp", type=float, default=None, help="è¦†ç›– profile.penalty_logp")

    # === åœ¨è¿™é‡Œæ’å…¥æ‚¨æ–°å¢çš„å‚æ•° ===
    parser.add_argument("--save_top_structures", action="store_true", default=True, 
                        help="æ˜¯å¦æå–å¹¶ä¿å­˜ Top N åˆ†å­çš„ 3D ç»“æ„æ–‡ä»¶")
    parser.add_argument("--top_n_save", type=int, default=20, 
                        help="æŒ‡å®šä¿å­˜å‰å¤šå°‘ä¸ªåˆ†å­çš„ç»“æ„")

    parser.add_argument("--write_intermediate_csv", action="store_true",
                        help="åœ¨ auto_predE3_stage2 ä¸‹ï¼Œå†™å‡º results/step4c_master_summary_SORTBY_predE3*.csv ä»¥ä¾¿å¤ç°")
    parser.add_argument("--no_write_intermediate_csv", action="store_true",
                        help="åœ¨ auto_predE3_stage2 ä¸‹ï¼Œä¸å†™ä¸­é—´ CSVï¼ˆé»˜è®¤ä¼šå†™ï¼‰")
    args = parser.parse_args()

    # ----------------- è¯»å– Step4C æ€»è¡¨ ----------------- #
    step4c_csv = args.step4c_csv or args.input_csv
    if not os.path.exists(step4c_csv):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°è¾“å…¥: {step4c_csv}")
    df4 = pd.read_csv(step4c_csv)
    if df4.empty:
        print("âš ï¸ Step4C è¾“å…¥ä¸ºç©ºï¼Œé€€å‡ºã€‚")
        return

    # ----------------- å¯é€‰ï¼šè‡ªåŠ¨ predE3 æ’åº + Stage2 guardrails ----------------- #
    if args.auto_predE3_stage2:
        # 1) ç»„è£… Stage2 é…ç½®ï¼ˆprofile + overrideï¼‰
        cfg = STAGE2_PROFILES.get(args.stage2_profile, STAGE2_PROFILES[DEFAULT_STAGE2_PROFILE]).copy()
        # overrides
        if args.stage2_pool is not None: cfg["pool"] = args.stage2_pool
        if args.stage2_mw_min is not None: cfg["mw_min"] = args.stage2_mw_min
        if args.stage2_tpsa_min is not None: cfg["tpsa_min"] = args.stage2_tpsa_min
        if args.stage2_hba_min is not None: cfg["hba_min"] = args.stage2_hba_min
        if args.stage2_soft_tpsa_target is not None: cfg["soft_tpsa_target"] = args.stage2_soft_tpsa_target
        if args.stage2_soft_logp_max is not None: cfg["soft_logp_max"] = args.stage2_soft_logp_max
        if args.stage2_penalty_tpsa is not None: cfg["penalty_tpsa"] = args.stage2_penalty_tpsa
        if args.stage2_penalty_logp is not None: cfg["penalty_logp"] = args.stage2_penalty_logp

        print(f"ğŸ§  auto_predE3_stage2=ON | stage2_profile={args.stage2_profile} | cfg={cfg}")

        # 2) è¯»å–å†å² docking æ ‡ç­¾
        dock_labels = _load_docking_labels(args.dock_csv_glob)
        print(f"ğŸ§ª predE3 labels loaded: {len(dock_labels)} unique smiles (glob={args.dock_csv_glob})")

        try:
            # 3) predE3 æ’åº
            df_ranked = _train_predE3_and_rank(
                step4c_df=df4,
                dock_labels=dock_labels,
                n_estimators=int(args.predE3_n_estimators),
                cv_splits=int(args.predE3_cv_splits),
                n_jobs=int(args.predE3_n_jobs),
                min_samples_leaf=int(PRED_E3_DEFAULT["min_samples_leaf"]),
                random_state=int(PRED_E3_DEFAULT["random_state"]),
            )

            # 4) Stage2 guardrails
            df = _apply_stage2_guardrails(
                df_ranked,
                cfg,
                use_strict_gate=bool(args.use_strict_gate),
                rphys_min=float(args.rphys_min)
            )

            # 5) å¯é€‰ï¼šå†™ä¸­é—´ CSVï¼ˆé»˜è®¤å†™ï¼Œé™¤éæ˜¾å¼ --no_write_intermediate_csvï¼‰
            do_write = (not args.no_write_intermediate_csv) or args.write_intermediate_csv
            if do_write:
                out1 = os.path.join(project_root, "results", "step4c_master_summary_SORTBY_predE3.csv")
                out2 = os.path.join(project_root, "results", "step4c_master_summary_SORTBY_predE3_stage2.csv")
                df_ranked.to_csv(out1, index=False)
                df.to_csv(out2, index=False)
                print(f"ğŸ“ wrote intermediates: {out1} | {out2}")

            print(f"ğŸ§± Stage2 kept rows: {len(df)} (after ADMET+pool+MW/TPSA/HBA + soft-penalty reorder)")
            if df.empty:
                print("âš ï¸ Stage2 è¿‡æ»¤åä¸ºç©ºï¼›å›é€€åˆ°åŸå§‹æ’åºï¼ˆR_globalï¼‰ã€‚")
                df = df4.copy()

        except Exception as e:
            print(f"âš ï¸ auto_predE3_stage2 failed ({e}); fallback to original ranking (R_global).")
            df = df4.copy()
    else:
        df = df4.copy()

    # === å†³èµ›åå•ç­›é€‰ (ç‰©ç†å¦å†³æƒæ ¸å¿ƒ) ===
    # ä¼˜å…ˆä½¿ç”¨ Is_Final_Topï¼Œç¡®ä¿åªæœ‰é€šè¿‡ DFT ç»ˆå®¡ä¸”ç¬¦åˆç‰©ç†/è¯ä»£æ ‡å‡†çš„åˆ†å­è¿›å…¥å¯¹æ¥
    # 1) å…¥å£ç­›é€‰ï¼šä¸¥æ ¼é—¨æ§›ä¼˜å…ˆï¼ˆå¾—åˆ° 36ï¼‰ï¼Œå¦åˆ™å›é€€ Is_Final_Top / Active_Set
    if args.use_strict_gate and all(c in df.columns for c in ["Data_Source_Status", "Physical_HardFail", "R_phys"]):
        df = df[
            (df["Data_Source_Status"] == "Step3c+4a+4b") &
            (df["Physical_HardFail"] == False) &
            (df["R_phys"] >= float(args.rphys_min))
        ].copy()
        print(f"âœ… ä¸¥æ ¼é—¨æ§›ç”Ÿæ•ˆï¼šä»…å¯¹é€šè¿‡ PySCF+DFT ä¸” R_phys>={args.rphys_min} çš„ {len(df)} ä¸ªåˆ†å­ dockingã€‚")

    elif "Is_Final_Top" in df.columns:
        df = df[df["Is_Final_Top"] == True].copy()
        print(f"âœ… ä½¿ç”¨ Is_Final_Topï¼š{len(df)} ä¸ªåˆ†å­ dockingã€‚")

    elif "Active_Set" in df.columns:
        df = df[(df["Active_Set"] == True) | (df["Active_Set"] == 1)].copy()
        print(f"âœ… ä½¿ç”¨ Active_Setï¼š{len(df)} ä¸ªåˆ†å­ dockingã€‚")
        if df.empty:
            print("âš ï¸ Active_Set ç­›é€‰åä¸ºç©ºï¼Œé€€å‡ºã€‚")
            return

    # é€‰æ‹© TopNï¼ˆè¿™é‡Œä»ä¿ç•™ TopNï¼šdocking æˆæœ¬å¤ªé«˜ï¼›ä½ ä¹Ÿå¯ä»¥æŠŠ top_n æ”¹å¤§ï¼‰
    preferred = ["R_global2", "R_total2", "R_total", "R_global", "Reward", "pIC50"]
    sort_col = choose_sort_col(df, preferred)
    
    if sort_col is None:
        sort_col = df.columns[0]
        df_sorted = df.copy()
    else:
        df_sorted = df.sort_values(sort_col, ascending=False).copy()

    df_top = df_sorted.head(args.top_n).copy()
    if "name" not in df_top.columns:
        df_top.insert(0, "name", [f"mol_{i}" for i in range(len(df_top))])

    print(f"ğŸ“¥ è¾“å…¥åˆ†å­æ•°: {len(df)} | é€‰æ‹© docking TopN={len(df_top)} | sort_by={sort_col}")

    # å—ä½“ä¼˜å…ˆä½¿ç”¨ *_gast_clean.pdbqtï¼Œå¹¶è‡ªåŠ¨æŒ‰ His41/Cys145 è®¡ç®— box center
    resolved_targets = build_resolved_target_config(args.receptor_dir)

    tmp_root = tempfile.mkdtemp(prefix="step5a_docking_")

    results: List[Dict[str, Any]] = []
    with concurrent.futures.ProcessPoolExecutor(max_workers=args.workers) as ex:
        futures = []
        for _, row in df_top.iterrows():
            futures.append(ex.submit(process_one_molecule, row, resolved_targets, tmp_root, args.vina_cpu))

        total = len(futures)
        done_cnt = 0
        for fut in concurrent.futures.as_completed(futures):
            done_cnt += 1
            res = fut.result()
            if res is not None:
                results.append(res)
                bs = res.get("Broad_Spectrum_Score")
                bs_str = f"{bs:.2f}" if bs is not None and np.isfinite(bs) else "NaN"
                print(f"[{done_cnt}/{total}] {res.get('name','')} BroadScore={bs_str}")
            else:
                print(f"[{done_cnt}/{total}] è¯¥åˆ†å­å¤„ç†å¤±è´¥")

    # --- æ’å…¥ç‚¹ï¼šåœ¨æ¸…ç† tmp ä¹‹å‰æå–ç»“æ„ ---
    # å…ˆæ£€æŸ¥æœ‰æ²¡æœ‰ç»“æœ
    if not results:
        print("âš ï¸ æ²¡æœ‰ä»»ä½•æˆåŠŸçš„ docking ç»“æœï¼Œæœªç”Ÿæˆè¾“å‡ºæ–‡ä»¶")
        # å¯é€‰ï¼šå¤±è´¥æ—¶ä¹Ÿæ¸…ç† tmp
        try:
            shutil.rmtree(tmp_root)
        except Exception:
            pass
        return

    # å…ˆåˆ›å»º df_resï¼ˆå…³é”®ï¼šåé¢ä¿å­˜ç»“æ„/æ’å/ä¿å­˜CSVéƒ½ä¾èµ–å®ƒï¼‰
    df_res = pd.DataFrame(results)

    # --- åœ¨æ¸…ç† tmp ä¹‹å‰æå–ç»“æ„ï¼ˆæ­¤æ—¶ df_res å·²å­˜åœ¨ï¼‰ ---
    if args.save_top_structures:
        save_top_n_structures(df_res, tmp_root, top_n=args.top_n_save)

    # æ¸…ç†ä¸´æ—¶ç›®å½•ï¼ˆå¯æŒ‰éœ€è¦ä¿ç•™ï¼‰
    try:
        shutil.rmtree(tmp_root)
    except Exception:
        pass


    # ç”Ÿæˆæ’ååˆ—ï¼ˆè¶Šè´Ÿè¶Šå¥½ -> å‡åºï¼‰
    df_res["Broad_Rank"] = df_res["Broad_Spectrum_Score"].rank(method="min", ascending=True)
    df_res["Broad_Rank_Pct"] = compute_rank_pct(df_res["Broad_Spectrum_Score"])

    # æ•´ç†åˆ—é¡ºåº
    base_cols = ["name", "smiles", "Broad_Spectrum_Score", "Broad_Rank", "Broad_Rank_Pct",
                 "E_SARS_CoV_2", "E_SARS_CoV_1", "E_MERS_CoV"]
    extra_cols = [c for c in df_res.columns if c not in base_cols]
    df_res = df_res[base_cols + extra_cols]

    os.makedirs(os.path.dirname(args.out_csv), exist_ok=True)
    df_res.to_csv(args.out_csv, index=False)

    print("\n========================================")
    print(f"âœ… å¹¿è°±å¯¹æ¥å®Œæˆï¼Œç»“æœå·²ä¿å­˜: {args.out_csv}")
    print(f"   docking åˆ†å­æ•°: {len(df_res)}")
    if df_res["Broad_Spectrum_Score"].notna().any():
        s = df_res["Broad_Spectrum_Score"].dropna()
        print(f"   Broad_Spectrum_Score: min={s.min():.3f} mean={s.mean():.3f} max={s.max():.3f}")
        best = df_res.sort_values("Broad_Spectrum_Score").iloc[0]
        print(f"   Top1: {best['name']} score={best['Broad_Spectrum_Score']:.3f}")
    print("========================================")


if __name__ == "__main__":
    main()
